{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data Validation Report for `validation_test_case`\n",
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The validation_test_case project is a test assignment focused on verifying the accuracy of an AI-based ticket classification system.\n",
    "The dataset contains tickets, which are customer reviews or opinions about a company (in this case, Booking).\n",
    "The system automatically classifies each ticket into five predefined topics and determines the sentiment for each topic (positive, negative, or neutral).\n",
    "\n",
    "The goal of this task is to validate the correctness of the system’s outputs in two key dimensions:\n",
    "\n",
    "Topic Volume Validation — Verify whether the number of tickets assigned to each topic matches the expected or actual values.\n",
    "\n",
    "Sentiment Validation — Assess the accuracy of sentiment classification (positive, negative, neutral) within each topic."
   ],
   "id": "f60b78efc34595da"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In the first part of report, I import data from two JSON files, validate their data, and eliminate the possibility of empty lines. In the second, I process and compare the obtained data. In the third, I display graphs demonstrating the data and draw a conclusion on the work done.",
   "id": "47f1148a8cb625cf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T11:44:27.119343Z",
     "start_time": "2025-11-01T11:44:27.107998Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "clean_tickets = pd.json_normalize(pd.read_json('json_file_for_validation/booking_reviews_clean.json')['tickets'])\n",
    "\n",
    "results_json = pd.read_json('json_file_for_validation/results_booking_reviews_clean.json')\n",
    "results_raw = results_json[\"gemini-2.5-flash\"]\n",
    "all_blocks = [item for sublist in results_raw for item in sublist]\n",
    "total_results_tickets_gemini = sum(len(sublist) for sublist in results_tickets[\"gemini-2.5-flash\"])\n",
    "results_rows = []\n",
    "for block in all_blocks:\n",
    "    for ex in block[\"examples\"]:\n",
    "        results_rows.append({\n",
    "            \"subtopic\": block[\"subtopic\"],\n",
    "            \"sentiment\": block[\"sentiment\"],\n",
    "            \"example_text\": ex.strip().lower(),})\n",
    "\n",
    "results_tickets_flat = pd.DataFrame(results_rows)\n",
    "\n",
    "print(f'Size clean_tickets is {clean_tickets.size}')\n",
    "print(clean_tickets.head(), end='\\n\\n')\n",
    "\n",
    "print(f'Size results_tickets is {results_tickets_flat.size}')\n",
    "print(results_tickets_flat.head(), end='\\n\\n')\n"
   ],
   "id": "359e35c403bef386",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size clean_tickets is 2034\n",
      "                                    original_message  \\\n",
      "0  Not to gush, but support has genuinely helped ...   \n",
      "1  Over the weekend, the rewards points actually ...   \n",
      "2  Not to gush, but support has genuinely helped ...   \n",
      "3  While traveling abroad, the app froze twice on...   \n",
      "4  For a family visit, the property was overbooke...   \n",
      "\n",
      "                                        message_text sentiment__filter  \n",
      "0  not to gush, but support has genuinely helped ...          Positive  \n",
      "1  over the weekend, the rewards points actually ...          Positive  \n",
      "2  not to gush, but support has genuinely helped ...          Positive  \n",
      "3  while traveling abroad, the app froze twice on...          Negative  \n",
      "4  for a family visit, the property was overbooke...          Negative  \n",
      "\n",
      "Size results_tickets is 2013\n",
      "                       subtopic sentiment  \\\n",
      "0  Unexpected Charges & Pricing  Negative   \n",
      "1  Unexpected Charges & Pricing  Negative   \n",
      "2  Unexpected Charges & Pricing  Negative   \n",
      "3  Unexpected Charges & Pricing  Negative   \n",
      "4  Unexpected Charges & Pricing  Negative   \n",
      "\n",
      "                              example_text  \n",
      "0                 price changed at payment  \n",
      "1                fees appeared at checkout  \n",
      "2                   hidden fees at the end  \n",
      "3                  promo code failed again  \n",
      "4  charged twice and had to chase a refund  \n",
      "\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Здесь я описываю дальнейшую логику, говорящую о том, что в результирующих данных большое количество дубликатов, которые полностью эквивалентны между собой.",
   "id": "cc2c2199f1aa6377"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Объяснение нижележащей функции.",
   "id": "aaeffa8a9fbda6bd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T11:38:32.316803Z",
     "start_time": "2025-11-01T11:38:32.302610Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import Counter\n",
    "\n",
    "df = clean_tickets.dropna(subset=['message_text'])\n",
    "\n",
    "sentiment_map = {}\n",
    "\n",
    "for text, group in df.groupby('message_text'):\n",
    "    sentiments = group['sentiment__filter'].tolist()\n",
    "    most_common = Counter(sentiments).most_common(1)[0][0]\n",
    "    sentiment_map[text] = most_common\n",
    "\n",
    "print(f\"Total number of unique texts: {len(sentiment_map)}\")\n",
    "\n",
    "print(\"Example 10 keys:\")\n",
    "for k in list(sentiment_map.keys())[:10]:\n",
    "    print(k, \"=>\", sentiment_map[k])"
   ],
   "id": "1818f5fb96f1025",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique texts: 358\n",
      "Example 10 keys:\n",
      "ads in notifications, annoying => Negative\n",
      "after comparing a few options, communication with the host was straightforward, and i appreciated the clarity. => Positive\n",
      "after comparing a few options, communication with the host was straightforward, so i'd use it again. => Positive\n",
      "after comparing a few options, customer support answered within minutes and fixed a date mistake, but there's still room for improvement. => Positive\n",
      "after comparing a few options, customer support answered within minutes and fixed a date mistake, so i'd use it again. => Positive\n",
      "after comparing a few options, customer support answered within minutes and fixed a date mistake, though i wish it were faster. => Positive\n",
      "after comparing a few options, fees appeared at checkout that weren't shown before, and i appreciated the clarity. => Negative\n",
      "after comparing a few options, fees appeared at checkout that weren't shown before, which made the whole process stress-free. => Negative\n",
      "after comparing a few options, filters worked fine but some listings lacked details, though i wish it were faster. => Neutral\n",
      "after comparing a few options, maps helped, but reviews varied a lot, and i appreciated the clarity. => Neutral\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Здесь я опишу, что, развернув хэш-мапу, я вывожу несоответствие, и я хочу перебрать каждый элемент из примеров и сравнить его с сентиметс в оригинале. Хожу вывести, где не совпадает, в каком настроении и по каким фразом, и я считаю это валидацией настроения. Также я выведу графики, какие у модели проебы, процент проебов общий, и в каких местах эти проебы были.",
   "id": "fd18a64309a72ef6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def check_sentiment(row):\n",
    "    raw_sent = sentiment_map.get(row['norm_text'])\n",
    "    if raw_sent is None:\n",
    "        return \"not_found\"\n",
    "    return \"match\" if raw_sent == row['sentiment'] else \"mismatch\"\n",
    "\n",
    "results_df['sentiment_check'] = results_df.apply(check_sentiment, axis=1)\n"
   ],
   "id": "7b447f313d180398"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
